{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_05-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaghuvamsiImadabattuni/Raghu-vamsi_INFO5731_Fall2021/blob/main/In_class_exercise_05_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3FqZ9X1b2qr"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8GwYAG4b2qw"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-3rQkq5z8xB"
      },
      "source": [
        "#importing requirements\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "hjocb5vje5Fo",
        "outputId": "26f9a2e3-bf9f-45d4-b589-a028ef00b49b"
      },
      "source": [
        "#Loading train data\n",
        "df = pd.read_csv(\"/content/stsa-train.txt\", engine='python', sep='delimiter', header=None)               \n",
        "df = pd.DataFrame(df) \n",
        "df.columns = [\"Reviews\"] \n",
        "df['Sentiment'] = df['Reviews'].str.split(' ').str[0]\n",
        "df['Reviews'] = df['Reviews'].str.split(n=1).str[1]\n",
        "df"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>painful , horrifying and oppressively tragic ,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6920 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Reviews Sentiment\n",
              "0     a stirring , funny and finally transporting re...         1\n",
              "1     apparently reassembled from the cutting-room f...         0\n",
              "2     they presume their audience wo n't sit still f...         0\n",
              "3     this is a visually stunning rumination on love...         1\n",
              "4     jonathan parker 's bartleby should have been t...         1\n",
              "...                                                 ...       ...\n",
              "6915  painful , horrifying and oppressively tragic ,...         1\n",
              "6916  take care is nicely performed by a quintet of ...         0\n",
              "6917  the script covers huge , heavy topics in a bla...         0\n",
              "6918  a seriously bad film with seriously warped log...         0\n",
              "6919  a deliciously nonsensical comedy about a city ...         1\n",
              "\n",
              "[6920 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "xW-DBZ6ScuNm",
        "outputId": "0c068173-c05e-46d5-bc82-e28a29e4c8bd"
      },
      "source": [
        "#Loading test data\n",
        "df_1 = pd.read_csv(\"/content/stsa-test.txt\", engine='python', sep='delimiter', header=None)               \n",
        "df_1 = pd.DataFrame(df_1) \n",
        "df_1.columns = [\"Reviews\"] \n",
        "df_1['Sentiment'] = df_1['Reviews'].str.split(' ').str[0]\n",
        "df_1['Reviews'] = df_1['Reviews'].str.split(n=1).str[1]\n",
        "df_1"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>an often-deadly boring , strange reading of a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1821 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Reviews Sentiment\n",
              "0        no movement , no yuks , not much of anything .         0\n",
              "1     a gob of drivel so sickly sweet , even the eag...         0\n",
              "2     gangs of new york is an unapologetic mess , wh...         0\n",
              "3     we never really feel involved with the story ,...         0\n",
              "4               this is one of polanski 's best films .         1\n",
              "...                                                 ...       ...\n",
              "1816  an often-deadly boring , strange reading of a ...         0\n",
              "1817  the problem with concept films is that if the ...         0\n",
              "1818  safe conduct , however ambitious and well-inte...         0\n",
              "1819  a film made with as little wit , interest , an...         0\n",
              "1820  but here 's the real damn : it is n't funny , ...         0\n",
              "\n",
              "[1821 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIjCji-Yb2q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa5af7e-d904-4ff1-d44c-232f729dcdca"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "nltk.download('stopwords') \n",
        "cp_train = [] \n",
        "for i in range(0, 6920): \n",
        "    text = re.sub('[^a-zA-Z]', '', df['Reviews'][i]) \n",
        "    text = text.lower() \n",
        "    text = text.split() \n",
        "    ps = PorterStemmer() \n",
        "    text = ''.join(text) \n",
        "    cp_train.append(text)\n",
        "cp_test = []\n",
        "for i in range(0, 1821): \n",
        "    text = re.sub('[^a-zA-Z]', '', df_1['Reviews'][i]) \n",
        "    text = text.lower() \n",
        "    text = text.split() \n",
        "    ps = PorterStemmer() \n",
        "    text = ''.join(text) \n",
        "    cp_test.append(text)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sYACxkKb2q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3356f49c-5258-45d2-b61d-9d45a4fa63c3"
      },
      "source": [
        "# creating model \n",
        "cv = CountVectorizer(max_features = 5000) \n",
        "X = cv.fit_transform(corpus_train).toarray() \n",
        "y = dataset.iloc[:, 1].values\n",
        "y"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '0', '0', ..., '0', '0', '1'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Lef3Pud33F"
      },
      "source": [
        "# splitting the data into training set and validation set \n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=123)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4k501O0eOl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ac371a-3e0a-4414-8d6e-575db117c0a7"
      },
      "source": [
        "#MultinomialNB \n",
        "import sklearn.metrics as metrics \n",
        "from sklearn.metrics import accuracy_score,recall_score, f1_score, precision_score \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classify = MultinomialNB()\n",
        "model = classify.fit(X_train, y_train)\n",
        "#Printing accuracy values\n",
        "print('accuracy: %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing values\n",
        "print(classification_report(y_test,y_pred))\n",
        "#calculating cross-validation scores\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(classifier, X_test, y_test, cv=10)\n",
        "print(\"multinomialNB: \",scores.mean())"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.26      0.50      0.35      1384\n",
            "weighted avg       0.28      0.53      0.37      1384\n",
            "\n",
            "multinomialNB 0.5006412261495152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7jeM4IFg5eS",
        "outputId": "88086ef8-6b51-41e0-9baf-a4ef999947a6"
      },
      "source": [
        "#SVM\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "model = clf.fit(X_train, y_train)\n",
        "print('accuracy: %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing values\n",
        "print(classification_report(y_test,y_pred))\n",
        "#calculating cross-validation scores\n",
        "scores = cross_val_score(clf, X_test, y_test, cv=10)\n",
        "print(\"SVM: \",scores.mean())"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.26      0.50      0.35      1384\n",
            "weighted avg       0.28      0.53      0.37      1384\n",
            "\n",
            "SVM:  0.5296215201751643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVbOyJeog9NT"
      },
      "source": [
        "#KNN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(X_train, y_train)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_val = scaler.transform(X_val)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewNbDerBhKEV",
        "outputId": "391c9b94-9dc5-40db-f07f-ae1e01615469"
      },
      "source": [
        "#Printing accuracy values\n",
        "print('accuracy: %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing values\n",
        "print(classification_report(y_test,y_pred))\n",
        "#calculating cross-validation scores\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(classifier, X_test, y_test, cv=10)\n",
        "print(\"KNN: \",scores.mean())"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.26      0.50      0.35      1384\n",
            "weighted avg       0.28      0.53      0.37      1384\n",
            "\n",
            "KNN:  0.5006412261495152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9gkJoebhS8N",
        "outputId": "99311442-df19-47d4-ea27-94aecd18ce65"
      },
      "source": [
        "#DECISION TREE\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.model_selection import train_test_split \n",
        "import sklearn.metrics as metrics \n",
        "# Creating classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "# Training Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "#Printing accuracy values\n",
        "print('accuracy: %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing values\n",
        "print(classification_report(y_test,y_pred))\n",
        "#For calculating the cross-validation scores\n",
        "scores = cross_val_score(clf, X_test, y_test, cv=10)\n",
        "print(\"Decision Tree: \",scores.mean())"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.26      0.50      0.35      1384\n",
            "weighted avg       0.28      0.53      0.37      1384\n",
            "\n",
            "Decision Tree:  0.5296215201751643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtk07jUuhZ83",
        "outputId": "1dce5bd1-686b-459d-ade6-363f5422df34"
      },
      "source": [
        "#RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sklearn.metrics as metrics\n",
        "#Creating Gaussian Classifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "#Training model\n",
        "clf.fit(X_train,y_train)\n",
        "#Printing values\n",
        "print('accuracy: %s' % accuracy_score(y_pred,y_test))\n",
        "#Comparing values\n",
        "print(classification_report(y_test,y_pred))\n",
        "#calculating cross-validation scores\n",
        "scores = cross_val_score(clf, X_test, y_test, cv=10)\n",
        "print(\"RANDOM FOREST: \",scores.mean())"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5296242774566474\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       651\n",
            "           1       0.53      1.00      0.69       733\n",
            "\n",
            "    accuracy                           0.53      1384\n",
            "   macro avg       0.26      0.50      0.35      1384\n",
            "weighted avg       0.28      0.53      0.37      1384\n",
            "\n",
            "RANDOM FOREST:  0.5296215201751643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1qpRKlXhhfx",
        "outputId": "166453e4-10cc-45ce-9745-79490dbf09b6"
      },
      "source": [
        "#XGBoost\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
        "xg_reg.fit(X_train,y_train)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:03:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=0.3, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=5, min_child_weight=1, missing=None, n_estimators=10,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCatX6fwb2qz"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K means, \n",
        "DBSCAN,\n",
        "Hierarchical clustering. \n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "xBPH3_LOhoaI",
        "outputId": "23b61414-6eac-49da-e7b8-044601177683"
      },
      "source": [
        "import pandas as pd\n",
        "ds = pd.read_csv(\"Amazon_Unlocked_Mobile.csv\")\n",
        "ds"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413835</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>5</td>\n",
              "      <td>another great deal great price</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413836</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>3</td>\n",
              "      <td>Ok</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413837</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>5</td>\n",
              "      <td>Passes every drop test onto porcelain tile!</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413838</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>3</td>\n",
              "      <td>I returned it because it did not meet my needs...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413839</th>\n",
              "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>79.95</td>\n",
              "      <td>4</td>\n",
              "      <td>Only downside is that apparently Verizon no lo...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>413840 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Product Name  ... Review Votes\n",
              "0       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          1.0\n",
              "1       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "2       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "3       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "4       \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "...                                                   ...  ...          ...\n",
              "413835  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "413836  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "413837  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "413838  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "413839  Samsung Convoy U640 Phone for Verizon Wireless...  ...          0.0\n",
              "\n",
              "[413840 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS51ewy2Z7KC",
        "outputId": "aefa4554-f5be-4d2a-a07d-0b67e31d9ba9"
      },
      "source": [
        "#Cleaning data\n",
        "ds= ds[ds['Reviews'].notnull()].head(5000)\n",
        "#Removing punctuatiions\n",
        "ds['punct'] = ds['Reviews'].str.replace('[^\\w\\s].#','')\n",
        "from nltk.corpus import stopwords\n",
        "import nltk \n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "#Removing stopwords \n",
        "ds['stopwords'] =ds['punct'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "#Removing numercis\n",
        "ds['numerics']=ds['stopwords'].str.replace('[0-9]','')\n",
        "#to lowercase\n",
        "ds['lowercase'] =ds['numerics'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "#Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "ds['stemming']=ds['lowercase'].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))\n",
        "#Lemmatizing\n",
        "from textblob import Word\n",
        "ds['clean'] = ds['stemming'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "ds['clean']"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       i feel lucki found use (phone u & use hard all...\n",
              "1       nice phone, nice grade pantach revue. veri cle...\n",
              "2                                               veri plea\n",
              "3         it work good goe slow sometim good phone i love\n",
              "4       great phone replac lost phone. the thing volum...\n",
              "                              ...                        \n",
              "4995    thi review product may find everywher www worl...\n",
              "4996    the product good structure. i'm still use braz...\n",
              "4997    the iphon fine. it work good condit one major ...\n",
              "4998                           screen crack realli quick.\n",
              "4999    will never buy anyth again. i receiv work. nei...\n",
              "Name: clean, Length: 5000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn_TliQTa14q",
        "outputId": "5855c5ef-33c5-45ae-c474-75d5f3078a3e"
      },
      "source": [
        "#Vectoring data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vector = TfidfVectorizer()\n",
        "tfidf = vector.fit_transform(ds['clean'].values)\n",
        "tfidf.shape"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 7567)"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wbpcsYqybB13",
        "outputId": "d340344d-b805-41cd-ad67-16c9b2a60fcb"
      },
      "source": [
        "#K means model \n",
        "from sklearn.cluster import KMeans\n",
        "#Defining k means model\n",
        "kmodel = KMeans(n_clusters = 5, n_jobs = -1,random_state=99)\n",
        "kmodel.fit(tfidf)\n",
        "#Creating labels \n",
        "labels_kmeans = kmodel.labels_\n",
        "#Defining tcluster center\n",
        "cluster_center_kmeans=kmodel.cluster_centers_\n",
        "terms = vector.get_feature_names()\n",
        "terms[1:10]\n",
        "ds['Label'] = kmodel.labels_\n",
        "ds"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>punct</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>numerics</th>\n",
              "      <th>lowercase</th>\n",
              "      <th>stemming</th>\n",
              "      <th>clean</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>very pleased</td>\n",
              "      <td>veri pleas</td>\n",
              "      <td>veri plea</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>it works good goes slow sometimes good phone i...</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>great phone replace lost phone. the thing volu...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>5</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>64.0</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>this review product may find everywhere www wo...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>4</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>157.0</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>the iphone fine. it works good condition one m...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>2</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>screen cracked really quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>will never buy anything again. i received work...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Product Name  ... Label\n",
              "0     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     0\n",
              "1     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     0\n",
              "2     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     0\n",
              "3     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     2\n",
              "4     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     0\n",
              "...                                                 ...  ...   ...\n",
              "4995     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "4996     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "4997     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "4998     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "4999     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "\n",
              "[5000 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb9--95EcIXO",
        "outputId": "c4119edd-d0cf-4d01-d99e-8737230914d2"
      },
      "source": [
        "#Counting clusters \n",
        "ds.groupby(['Label'])['clean'].count()"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    4211\n",
              "1     259\n",
              "2     198\n",
              "3     213\n",
              "4     119\n",
              "Name: clean, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NhAQCyAcko4",
        "outputId": "f3a54c49-fb77-4ea0-b6d8-47a5a11cf86c"
      },
      "source": [
        "#Finding top terms\n",
        "print(\"Top terms:\")\n",
        "#Defing the centroid model\n",
        "centroids = kmodel.cluster_centers_.argsort()[:, ::-1]\n",
        "#Creating the loop for finding the top words\n",
        "for i in range(5):\n",
        "    print(\"Cluster %d:\" % i, end='')\n",
        "    for ind in centroids[i, :5]:\n",
        "        print(' %s' % terms[ind], end='')\n",
        "        print()"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top terms:\n",
            "Cluster 0: phone\n",
            " it\n",
            " work\n",
            " the\n",
            " good\n",
            "Cluster 1: great\n",
            " work\n",
            " phone\n",
            " product\n",
            " price\n",
            "Cluster 2: good\n",
            " veri\n",
            " phone\n",
            " it\n",
            " product\n",
            "Cluster 3: love\n",
            " it\n",
            " phone\n",
            " great\n",
            " daughter\n",
            "Cluster 4: excel\n",
            " product\n",
            " recommend\n",
            " seller\n",
            " phone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu2ykF9yc4_Z"
      },
      "source": [
        "#DBscan Clustering\n",
        "from sklearn.cluster import DBSCAN\n",
        "points = 2 * 100\n",
        "def lower_b(nums, targ): \n",
        "    l, r = 0, len(nums) - 1\n",
        "    while l <= r: \n",
        "        mid = int(l + (r - l) / 2)\n",
        "        if nums[mid] >= targ:\n",
        "            r = mid - 1\n",
        "        else:\n",
        "            l = mid + 1\n",
        "    return l\n",
        "def com_200th_near_tneigh(x, data): \n",
        "    dists = []\n",
        "    for val in data:\n",
        "        dist = np.sum((x - val) **2 ) \n",
        "        if(len(dists) == 200 and dists[199] > dist): \n",
        "            l = int(lower_b(dists, dist)) \n",
        "            if l < 200 and l >= 0 and dists[l] > dist:\n",
        "                dists[l] = dist\n",
        "        else:\n",
        "            dists.append(dist)\n",
        "            dists.sort()\n",
        "    \n",
        "    return dists[199]"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yhuW_E4diBc"
      },
      "source": [
        "import numpy as np\n",
        "sent_vectors = []; \n",
        "for sent in ds['Reviews']: \n",
        "    sent_vec = np.zeros(100) \n",
        "    words =0; \n",
        "    for word in sent: \n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            sent_vec += vec\n",
        "            words += 1\n",
        "        except:\n",
        "            pass\n",
        "    sent_vec /= words\n",
        "    sent_vectors.append(sent_vec)"
      ],
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nHb3BRNhhXRW",
        "outputId": "c313c2b1-21dd-4f48-b43f-7632718efc47"
      },
      "source": [
        "sent_vectors = np.array(sent_vectors)\n",
        "sent_vectors = np.nan_to_num(sent_vectors)\n",
        "sent_vectors.shape\n",
        "points = 2 * 100\n",
        "model = DBSCAN(eps = 1, min_samples = points, n_jobs=-1)\n",
        "model.fit(sent_vectors)\n",
        "ds['AVG Clus Label'] = model.labels_\n",
        "ds"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>punct</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>numerics</th>\n",
              "      <th>lowercase</th>\n",
              "      <th>stemming</th>\n",
              "      <th>clean</th>\n",
              "      <th>Label</th>\n",
              "      <th>AVG Clus Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>very pleased</td>\n",
              "      <td>veri pleas</td>\n",
              "      <td>veri plea</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>it works good goes slow sometimes good phone i...</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>great phone replace lost phone. the thing volu...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>5</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>64.0</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>this review product may find everywhere www wo...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>4</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>157.0</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>the iphone fine. it works good condition one m...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>2</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>screen cracked really quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>will never buy anything again. i received work...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Product Name  ... AVG Clus Label\n",
              "0     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "1     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "2     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "3     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "4     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "...                                                 ...  ...            ...\n",
              "4995     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4996     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4997     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4998     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4999     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "\n",
              "[5000 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U00rcEG_l8xT"
      },
      "source": [
        "#Hierarchical clustering Model\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "#Defining model\n",
        "cluster = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')  \n",
        "Agg=cluster.fit_predict(sent_vectors)"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "mQeIHvKImQRE",
        "outputId": "2791d028-7c00-4611-90b8-f968e4a53eeb"
      },
      "source": [
        "#assigning Labels \n",
        "aggdfa = ds\n",
        "aggdfa['AVG Clus Label'] = cluster.labels_\n",
        "aggdfa.head()"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>punct</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>numerics</th>\n",
              "      <th>lowercase</th>\n",
              "      <th>stemming</th>\n",
              "      <th>clean</th>\n",
              "      <th>Label</th>\n",
              "      <th>AVG Clus Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>very pleased</td>\n",
              "      <td>veri pleas</td>\n",
              "      <td>veri plea</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>it works good goes slow sometimes good phone i...</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>great phone replace lost phone. the thing volu...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Product Name  ... AVG Clus Label\n",
              "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j510ScLomaKR",
        "outputId": "57c2c9b5-e583-45c2-c401-e7f95f2b7d95"
      },
      "source": [
        "aggdfa.groupby(['Label'])['clean'].count()"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    4211\n",
              "1     259\n",
              "2     198\n",
              "3     213\n",
              "4     119\n",
              "Name: clean, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgpp_USgmeUw",
        "outputId": "790be510-94cc-49bb-f362-e4d46ef4e4b6"
      },
      "source": [
        "for i in range(2):\n",
        "    print(\"Reviews  \", i)\n",
        "    print(\"-\" * 50)\n",
        "    print(aggdfa.iloc[aggdfa.groupby(['Label']).groups[i][0]]['clean'])\n",
        "    print('\\n')\n",
        "    print(aggdfa.iloc[aggdfa.groupby(['Label']).groups[i][1]]['clean'])\n",
        "    print('\\n')\n",
        "    print(\"_\" * 50)"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews   0\n",
            "--------------------------------------------------\n",
            "i feel lucki found use (phone u & use hard all), phone line someon upgrad sold one. my son like old one final fell apart .+ year want upgrade!! thank seller, realli appreci & honesti re: said use phone.i recommend seller highli & would again!!\n",
            "\n",
            "\n",
            "nice phone, nice grade pantach revue. veri clean set easi set up. never android phone fantast say least. perfect size surf social media. great phone samsung\n",
            "\n",
            "\n",
            "__________________________________________________\n",
            "Reviews   1\n",
            "--------------------------------------------------\n",
            "phone good littl slow phone old great phone temporari right now. thank great deal\n",
            "\n",
            "\n",
            "phone work great. no problem\n",
            "\n",
            "\n",
            "__________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuzUFOEGb2q0"
      },
      "source": [
        "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOCC6u1Ts0Nx"
      },
      "source": [
        "'''\n",
        "K-means Clustering should be more or less spherical or convex  and  have the same feature size when compared toThe formed clusters have any shape and may not have the same feature size. Hierarchical clustering cannot handle big data properly, but K-means clustering can. This is because the time complexity of the K-means method is linear, while the time complexity of hierarchical clustering is quadratic.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}